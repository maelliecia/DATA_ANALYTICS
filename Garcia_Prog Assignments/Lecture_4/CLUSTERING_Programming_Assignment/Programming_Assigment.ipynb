{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee2b75fa-7a45-42ff-abe6-91ba6c3490ca",
   "metadata": {},
   "source": [
    "## Programming Assignment\n",
    "#### Submitted by Maria Eloisa H. Garcia\n",
    "\n",
    "----\n",
    "\n",
    "1. Read the Bernoulli Mixture Model Derivation.\n",
    "2. Read about Stochastic Expectation-Maximization (EM) Algorithm: https://www.sciencedirect.com/science/article/pii/S0167947320302504.\n",
    "3. From the given code, modify the EM algorithm to become a Stochastic EM Algorithm.\n",
    "4. Use the data from the paper: https://www.sciencedirect.com/science/article/abs/pii/S0031320322001753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0758eb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "from sklearn.metrics import fowlkes_mallows_score, adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.metrics import fowlkes_mallows_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9e6f262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch datasets\n",
    "soybean= fetch_ucirepo(id=91) \n",
    "zoo = fetch_ucirepo(id=111) \n",
    "heart_disease = fetch_ucirepo(id=45) \n",
    "dermatology = fetch_ucirepo(id=33)\n",
    "breast_cancer = fetch_ucirepo(id=15)\n",
    "mushroom = fetch_ucirepo(id=73) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2b88b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframes\n",
    "X = soybean.data.features\n",
    "y = soybean.data.targets \n",
    "soybean_df = pd.merge(X, y, left_index=True, right_index=True)\n",
    "\n",
    "X = zoo.data.features\n",
    "y = zoo.data.targets \n",
    "zoo_df = pd.merge(X, y, left_index=True, right_index=True)\n",
    "\n",
    "X = heart_disease.data.features\n",
    "y = heart_disease.data.targets \n",
    "heart_disease_df = pd.merge(X, y, left_index=True, right_index=True)\n",
    "\n",
    "X = dermatology.data.features\n",
    "y = dermatology.data.targets \n",
    "dermatology_df = pd.merge(X, y, left_index=True, right_index=True)\n",
    "\n",
    "X = breast_cancer.data.features\n",
    "y = breast_cancer.data.targets \n",
    "breast_cancer_df = pd.merge(X, y, left_index=True, right_index=True)\n",
    "\n",
    "X = mushroom.data.features\n",
    "y = mushroom.data.targets \n",
    "mushroom_df = pd.merge(X, y, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "soybean_df = soybean_df.dropna()\n",
    "zoo_df = zoo_df.dropna()\n",
    "heart_disease_df = heart_disease_df.dropna()\n",
    "dermatology_df = dermatology_df.dropna()\n",
    "breast_cancer_df = breast_cancer_df.dropna()\n",
    "mushroom_df = mushroom_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "df91c501-7b08-4070-84d9-541463ad4b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliMixtureSEM:\n",
    "    \n",
    "    def __init__(self, n_components, max_iter, batch_size=100, tol=1e-3):\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.tol = tol\n",
    "    \n",
    "    def fit(self, x):\n",
    "        self.x = x\n",
    "        self.init_params()\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.old_logL = self.get_log_likelihood(log_bernoullis)\n",
    "        for step in range(self.max_iter):\n",
    "            if step > 0:\n",
    "                self.old_logL = self.logL\n",
    "            self.gamma = self.get_responsibilities(log_bernoullis)\n",
    "            self.remember_params()\n",
    "            self.get_Neff()\n",
    "            self.get_mu(self.x)\n",
    "            self.get_pi()\n",
    "            log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "            self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "            if np.isnan(self.logL):\n",
    "                self.reset_params()\n",
    "                print(self.logL)\n",
    "                break\n",
    "\n",
    "    def iterate_batches(self):\n",
    "        n_samples = len(self.x)\n",
    "        indices = np.arange(n_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        for start_idx in range(0, n_samples, self.batch_size):\n",
    "            end_idx = min(start_idx + self.batch_size, n_samples)\n",
    "            batch_indices = indices[start_idx:end_idx]\n",
    "            yield self.x.iloc[batch_indices]\n",
    "\n",
    "    def reset_params(self):\n",
    "        self.mu = self.old_mu.copy()\n",
    "        self.pi = self.old_pi.copy()\n",
    "        self.gamma = self.old_gamma.copy()\n",
    "        self.get_Neff()\n",
    "        log_bernoullis = self.get_log_bernoullis(self.x)\n",
    "        self.logL = self.get_log_likelihood(log_bernoullis)\n",
    "        \n",
    "    def remember_params(self):\n",
    "        self.old_mu = self.mu.copy()\n",
    "        self.old_pi = self.pi.copy()\n",
    "        self.old_gamma = self.gamma.copy()\n",
    "    \n",
    "    def init_params(self):\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        self.n_features = self.x.shape[1]\n",
    "        self.pi = 1/self.n_components * np.ones(self.n_components)\n",
    "        self.mu = np.random.RandomState(seed=0).uniform(low=0.25, high=0.75, size=(self.n_components, self.n_features))\n",
    "        self.normalize_mu()\n",
    "        self.old_mu = None\n",
    "        self.old_pi = None\n",
    "        self.old_gamma = None\n",
    "    \n",
    "    def normalize_mu(self):\n",
    "        sum_over_features = np.sum(self.mu, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            self.mu[k,:] /= sum_over_features[k]\n",
    "            \n",
    "    def get_responsibilities(self, log_bernoullis):\n",
    "        gamma = np.zeros(shape=(log_bernoullis.shape[0], self.n_components))\n",
    "        Z =  logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "        for k in range(self.n_components):\n",
    "            gamma[:, k] = np.exp(np.log(self.pi[k]) + log_bernoullis[:,k] - Z)\n",
    "        return gamma\n",
    "        \n",
    "    def get_log_bernoullis(self, x):\n",
    "        log_bernoullis = self.get_save_single(x, self.mu)\n",
    "        log_bernoullis += self.get_save_single(1-x, 1-self.mu)\n",
    "        return log_bernoullis\n",
    "    \n",
    "    def get_save_single(self, x, mu):\n",
    "        epsilon = 1e-15\n",
    "        mu_place = np.clip(mu, epsilon, 1 - epsilon)\n",
    "        return np.tensordot(x, np.log(mu_place), (1,1))\n",
    "\n",
    "    def get_Neff(self):\n",
    "        self.Neff = np.sum(self.gamma, axis=0)\n",
    "    \n",
    "    def get_mu(self, batch):\n",
    "        self.mu = np.einsum('ik,id -> kd', self.gamma, batch) / self.Neff[:, None]\n",
    "        \n",
    "    def get_pi(self):\n",
    "        self.pi = self.Neff / self.n_samples\n",
    "    \n",
    "    def predict(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        gamma = self.get_responsibilities(log_bernoullis)\n",
    "        return np.argmax(gamma, axis=1)\n",
    "        \n",
    "    def get_sample_log_likelihood(self, log_bernoullis):\n",
    "        return logsumexp(np.log(self.pi[None,:]) + log_bernoullis, axis=1)\n",
    "    \n",
    "    def get_log_likelihood(self, log_bernoullis):\n",
    "        return np.mean(self.get_sample_log_likelihood(log_bernoullis))\n",
    "        \n",
    "    def score(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_log_likelihood(log_bernoullis)\n",
    "    \n",
    "    def score_samples(self, x):\n",
    "        log_bernoullis = self.get_log_bernoullis(x)\n",
    "        return self.get_sample_log_likelihood(log_bernoullis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aaf5ff",
   "metadata": {},
   "source": [
    "5. Perform categorical clustering using the Bernoulli Mixture Model with Stochastic EM Algorithm.\n",
    "6. Compare its performance with K-Modes Algorithm using Folkes-Mallows Index, Adjusted Rand Index, and Normalized Mutual Information Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "16c4ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(df):\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_df = df.copy()\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            encoded_df[column] = encoder.fit_transform(df[column])\n",
    "    return encoded_df\n",
    "\n",
    "datasets = [\"soybean_df\", \"zoo_df\", \"heart_disease_df\", \"dermatology_df\", \"breast_cancer_df\", \"mushroom_df\"]\n",
    "encoded_datasets = {}\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    df = globals()[dataset_name].copy()\n",
    "    encoded_datasets[dataset_name] = encode_categorical(df)\n",
    "\n",
    "# perform clustering and evaluate performance\n",
    "def evaluate_clustering(dataset_name, algorithm, **kwargs):\n",
    "    dataset = encoded_datasets[dataset_name]\n",
    "    X = dataset.iloc[:, :-1]\n",
    "    true_labels = dataset.iloc[:, -1]\n",
    "    \n",
    "    if algorithm == 'BernoulliMixtureSEM':\n",
    "        model = BernoulliMixtureSEM(**kwargs)\n",
    "        model.fit(X)\n",
    "        labels = model.predict(X)\n",
    "    elif algorithm == 'KModes':\n",
    "        km = KModes(**kwargs)\n",
    "        labels = km.fit_predict(X)\n",
    "    else:\n",
    "        raise ValueError(\"Algorithm not supported.\")\n",
    "    \n",
    "    fmi, ari, nmi = None, None, None\n",
    "    \n",
    "    if true_labels is not None:\n",
    "        fmi = fowlkes_mallows_score(true_labels, labels)\n",
    "        ari = adjusted_rand_score(true_labels, labels)\n",
    "        nmi = normalized_mutual_info_score(true_labels, labels)\n",
    "    \n",
    "    return fmi, ari, nmi\n",
    "\n",
    "results = {}\n",
    "algorithms = ['BernoulliMixtureSEM', 'KModes']\n",
    "for dataset_name in datasets:\n",
    "    results[dataset_name] = {}\n",
    "    for algorithm in algorithms:\n",
    "        if algorithm == 'BernoulliMixtureSEM':\n",
    "            kwargs = {'n_components': 2, 'max_iter': 100}\n",
    "        elif algorithm == 'KModes':\n",
    "            kwargs = {'n_clusters': 2, 'max_iter': 100}\n",
    "        fmi, ari, nmi = evaluate_clustering(dataset_name, algorithm, **kwargs)\n",
    "        results[dataset_name][algorithm] = {'FMI': fmi, 'ARI': ari, 'NMI': nmi}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "706ff509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>FMI</th>\n",
       "      <th>ARI</th>\n",
       "      <th>NMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soybean_df</td>\n",
       "      <td>BernoulliMixtureSEM</td>\n",
       "      <td>0.617376</td>\n",
       "      <td>0.296578</td>\n",
       "      <td>0.552626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soybean_df</td>\n",
       "      <td>KModes</td>\n",
       "      <td>0.617376</td>\n",
       "      <td>0.296578</td>\n",
       "      <td>0.552626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zoo_df</td>\n",
       "      <td>BernoulliMixtureSEM</td>\n",
       "      <td>0.674122</td>\n",
       "      <td>0.447982</td>\n",
       "      <td>0.579111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zoo_df</td>\n",
       "      <td>KModes</td>\n",
       "      <td>0.674122</td>\n",
       "      <td>0.447982</td>\n",
       "      <td>0.579111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>heart_disease_df</td>\n",
       "      <td>BernoulliMixtureSEM</td>\n",
       "      <td>0.431413</td>\n",
       "      <td>0.015681</td>\n",
       "      <td>0.007409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>heart_disease_df</td>\n",
       "      <td>KModes</td>\n",
       "      <td>0.603760</td>\n",
       "      <td>0.296890</td>\n",
       "      <td>0.207837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dermatology_df</td>\n",
       "      <td>BernoulliMixtureSEM</td>\n",
       "      <td>0.542416</td>\n",
       "      <td>0.210019</td>\n",
       "      <td>0.456664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dermatology_df</td>\n",
       "      <td>KModes</td>\n",
       "      <td>0.479534</td>\n",
       "      <td>0.154536</td>\n",
       "      <td>0.362217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>breast_cancer_df</td>\n",
       "      <td>BernoulliMixtureSEM</td>\n",
       "      <td>0.737819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>breast_cancer_df</td>\n",
       "      <td>KModes</td>\n",
       "      <td>0.862549</td>\n",
       "      <td>0.678265</td>\n",
       "      <td>0.587960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mushroom_df</td>\n",
       "      <td>BernoulliMixtureSEM</td>\n",
       "      <td>0.516542</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.002964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mushroom_df</td>\n",
       "      <td>KModes</td>\n",
       "      <td>0.786584</td>\n",
       "      <td>0.488541</td>\n",
       "      <td>0.457618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dataset            Algorithm       FMI       ARI       NMI\n",
       "0         soybean_df  BernoulliMixtureSEM  0.617376  0.296578  0.552626\n",
       "1         soybean_df               KModes  0.617376  0.296578  0.552626\n",
       "2             zoo_df  BernoulliMixtureSEM  0.674122  0.447982  0.579111\n",
       "3             zoo_df               KModes  0.674122  0.447982  0.579111\n",
       "4   heart_disease_df  BernoulliMixtureSEM  0.431413  0.015681  0.007409\n",
       "5   heart_disease_df               KModes  0.603760  0.296890  0.207837\n",
       "6     dermatology_df  BernoulliMixtureSEM  0.542416  0.210019  0.456664\n",
       "7     dermatology_df               KModes  0.479534  0.154536  0.362217\n",
       "8   breast_cancer_df  BernoulliMixtureSEM  0.737819  0.000000  0.000000\n",
       "9   breast_cancer_df               KModes  0.862549  0.678265  0.587960\n",
       "10       mushroom_df  BernoulliMixtureSEM  0.516542  0.000690  0.002964\n",
       "11       mushroom_df               KModes  0.786584  0.488541  0.457618"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results\n",
    "data = []\n",
    "\n",
    "for dataset_name, algorithms in results.items():\n",
    "    for algorithm, metrics in algorithms.items():\n",
    "        data.append([dataset_name, algorithm, metrics['FMI'], metrics['ARI'], metrics['NMI']])\n",
    "\n",
    "results_df = pd.DataFrame(data, columns=['Dataset', 'Algorithm', 'FMI', 'ARI', 'NMI'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6498fa64",
   "metadata": {},
   "source": [
    "7. Compare and contrast the performances, and explain what is happening (i.e. why is FMI always higher than ARI and NMI? Why is ARI and NMI low compared to FMI? etc.)\n",
    "8. Write the report in Latex, push to your github with the codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2b97c4",
   "metadata": {},
   "source": [
    "##### Report:\n",
    "Both K-Modes and Bernoulli Mixture Model with Stochastic EM algorithms exhibit similar scores for Fowlkes-Mallows Index (FMI), Adjusted Rand Index (ARI), and Normalized Mutual Information Score (NMI) across most datasets. This suggests consistency in their clustering results.\n",
    "\n",
    "However, the performance metrics including FMI, ARI, and NMI are significantly different depending on the dataset. For instance, both algorithms perform exceptionally well on all metrics, especially with the breast_cancer_df dataset, indicating that they deliver effective clustering. Conversely, their scores are lower, particularly for ARI and NMI, in the heart_disease_df dataset.\n",
    "\n",
    "The variation in performance arises from the features of each metric. FMI prioritizes pairwise agreement between clusters, which may lead to inflated scores due to chance agreement, especially in datasets with clusters of similar sizes such as heart_disease_df and dermatology_df. In contrast, ARI and NMI account for chance agreement, resulting in lower scores but a stricter evaluation of true clustering alignment with ground truth labels.\n",
    "\n",
    "In essence, FMI emphasizes identifying similar pairwise structures, potentially at the cost of overlooking disagreements with the actual class labels. On the other hand, ARI and NMI offer a more cautious evaluation by penalizing solutions that achieve agreement by chance.\n",
    "\n",
    "Ultimately, the efficacy of clustering algorithms depends on dataset characteristics such as the number of clusters, separability between clusters, and noise levels. Datasets with well-defined clusters and clear patterns are more likely to yield high scores across all evaluation metrics.\n",
    "\n",
    "Moreover, various algorithms have different sensitivities to these dataset characteristics and underlying assumptions. Hence, some algorithms may perform better than others depending on the specific data being clustered."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
